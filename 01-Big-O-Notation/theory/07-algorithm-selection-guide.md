# Algorithm Selection Guide

**Navigation:** [ğŸ  Home](../../README.md) > [ğŸ“š Big O Notation](../README.md) > [ğŸ“– Theory](./00-index.md) > Algorithm Selection Guide

This guide will help you choose the most appropriate algorithm based on your specific requirements and constraints. Understanding Big O helps you make informed decisions about algorithm selection.

## Searching Algorithms

| Algorithm | Time Complexity | Space Complexity | Best For | Avoid When |
|-----------|----------------|------------------|----------|------------|
| **Linear Search** | O(n) | O(1) | Unsorted data<br>Small datasets | Large sorted datasets |
| **Binary Search** | O(log n) | O(1) iterative<br>O(log n) recursive | Sorted data<br>Large datasets | Unsorted data<br>Frequent updates |
| **Hash-based Search** | O(1) average | O(n) | Frequent lookups<br>Key-value pairs | Order matters<br>Memory constrained |
| **Breadth-First Search** | O(V+E) | O(V) | Shortest path<br>Level-by-level traversal | Deep graphs<br>Memory constraints |
| **Depth-First Search** | O(V+E) | O(h) where h is height | Path existence<br>Maze solving<br>Deep graphs | Shortest path<br>Level order needed |

### Decision Tree for Searching

```
Is your data sorted?
â”œâ”€â”€ Yes â†’ Do you need to find an exact match?
â”‚       â”œâ”€â”€ Yes â†’ Use Binary Search O(log n)
â”‚       â””â”€â”€ No â†’ Do you need to find closest value?
â”‚             â”œâ”€â”€ Yes â†’ Use Binary Search with modification
â”‚             â””â”€â”€ No â†’ Do you need range queries?
â”‚                   â”œâ”€â”€ Yes â†’ Consider B-Tree or similar O(log n)
â”‚                   â””â”€â”€ No â†’ Binary Search probably sufficient
â”‚
â””â”€â”€ No â†’ Can you afford to sort first?
        â”œâ”€â”€ Yes â†’ Sort + Binary Search: O(n log n) + O(log n)
        â””â”€â”€ No â†’ Do you have unique keys?
              â”œâ”€â”€ Yes â†’ Hash Table O(1) average
              â””â”€â”€ No â†’ Linear Search O(n)
```

## Sorting Algorithms

| Algorithm | Time Complexity | Space Complexity | Stable | Best For | Avoid When |
|-----------|----------------|------------------|--------|----------|------------|
| **Bubble Sort** | O(nÂ²) | O(1) | Yes | Educational purposes<br>Nearly sorted data<br>Tiny arrays | Performance matters<br>Large arrays |
| **Insertion Sort** | O(nÂ²) | O(1) | Yes | Small datasets<br>Nearly sorted data<br>Online (streaming) | Large unsorted arrays |
| **Selection Sort** | O(nÂ²) | O(1) | No | Simple implementation<br>Minimizing writes | Large arrays<br>When stability matters |
| **Merge Sort** | O(n log n) | O(n) | Yes | Guaranteed performance<br>Linked lists<br>External sorting<br>Stability needed | Memory constraints<br>Simple cases |
| **Quick Sort** | O(n log n) average<br>O(nÂ²) worst | O(log n) | No* | In-place sorting<br>Average performance<br>Cache efficiency | Stability required<br>Worst case unacceptable |
| **Heap Sort** | O(n log n) | O(1) | No | Memory constraints<br>Guaranteed performance | Stability required |
| **Counting Sort** | O(n+k) | O(n+k) | Yes | Small range of integers<br>k << n | Large range of values<br>Non-integer data |
| **Radix Sort** | O(d(n+k)) | O(n+k) | Yes | Large integers<br>Strings | When comparisons are cheap |

### Decision Tree for Sorting

```
How much data are you sorting?
â”œâ”€â”€ Small amount (n < 50)
â”‚     â”œâ”€â”€ Is the data nearly sorted? â†’ Insertion Sort
â”‚     â””â”€â”€ Random data â†’ Any sort works, Insertion often fast in practice
â”‚
â”œâ”€â”€ Medium amount
â”‚     â”œâ”€â”€ Is stability required?
â”‚     â”‚     â”œâ”€â”€ Yes â†’ Merge Sort
â”‚     â”‚     â””â”€â”€ No â†’ Quick Sort (with good pivot selection)
â”‚     â”‚
â”‚     â””â”€â”€ Memory constrained?
â”‚           â”œâ”€â”€ Yes â†’ Heap Sort
â”‚           â””â”€â”€ No â†’ Merge Sort or Quick Sort
â”‚
â””â”€â”€ Large amount
      â”œâ”€â”€ Are elements integers in small range?
      â”‚     â”œâ”€â”€ Yes â†’ Counting Sort or Radix Sort
      â”‚     â””â”€â”€ No â†’ Continue...
      â”‚
      â”œâ”€â”€ External sorting needed?
      â”‚     â”œâ”€â”€ Yes â†’ Merge Sort based external sort
      â”‚     â””â”€â”€ No â†’ Continue...
      â”‚
      â”œâ”€â”€ Is stability required?
      â”‚     â”œâ”€â”€ Yes â†’ Merge Sort
      â”‚     â””â”€â”€ No â†’ Quick Sort or Heap Sort
      â”‚
      â””â”€â”€ Memory constrained?
            â”œâ”€â”€ Yes â†’ Heap Sort
            â””â”€â”€ No â†’ Merge Sort or Quick Sort
```

## Graph Algorithms

| Algorithm | Time Complexity | Space Complexity | Best For | Avoid When |
|-----------|----------------|------------------|----------|------------|
| **Breadth-First Search** | O(V+E) | O(V) | Shortest path (unweighted)<br>Connected components<br>Level order traversal | Memory constraints<br>Deep graphs |
| **Depth-First Search** | O(V+E) | O(V) | Path finding<br>Topological sorting<br>Cycle detection | Shortest path needed<br>Wide graphs |
| **Dijkstra's Algorithm** | O(VÂ²) or O((V+E)log V) with heap | O(V) | Single-source shortest path<br>Positive weights only | Negative edges<br>All pairs needed |
| **Bellman-Ford** | O(VÂ·E) | O(V) | Single-source shortest path<br>Can handle negative edges | Performance critical<br>No negative cycles expected |
| **Floyd-Warshall** | O(VÂ³) | O(VÂ²) | All-pairs shortest paths<br>Dense graphs | Very large graphs<br>Sparse graphs |
| **Kruskal's Algorithm** | O(E log E) | O(V) | Minimum spanning tree<br>Sparse graphs | Dense graphs |
| **Prim's Algorithm** | O(VÂ²) or O(E log V) with heap | O(V) | Minimum spanning tree<br>Dense graphs | Very sparse graphs |
| **Topological Sort** | O(V+E) | O(V) | Dependency ordering<br>Task scheduling | Cyclic graphs |

### Decision Tree for Graph Problems

```
What type of graph problem are you solving?
â”œâ”€â”€ Finding a path
â”‚     â”œâ”€â”€ Shortest path?
â”‚     â”‚     â”œâ”€â”€ Unweighted graph â†’ BFS
â”‚     â”‚     â””â”€â”€ Weighted graph
â”‚     â”‚           â”œâ”€â”€ Negative weights?
â”‚     â”‚           â”‚     â”œâ”€â”€ Yes â†’ Bellman-Ford
â”‚     â”‚           â”‚     â””â”€â”€ No â†’ Dijkstra's Algorithm
â”‚     â”‚           â”‚
â”‚     â”‚           â””â”€â”€ Need all pairs?
â”‚     â”‚                 â”œâ”€â”€ Yes â†’ Floyd-Warshall
â”‚     â”‚                 â””â”€â”€ No â†’ Dijkstra's Algorithm
â”‚     â”‚
â”‚     â””â”€â”€ Just any path? â†’ DFS usually simpler
â”‚
â”œâ”€â”€ Traversal order matters?
â”‚     â”œâ”€â”€ Level order/breadth â†’ BFS
â”‚     â””â”€â”€ Deep exploration â†’ DFS
â”‚
â”œâ”€â”€ Finding minimum spanning tree
â”‚     â”œâ”€â”€ Dense graph â†’ Prim's Algorithm
â”‚     â””â”€â”€ Sparse graph â†’ Kruskal's Algorithm
â”‚
â”œâ”€â”€ Finding cycles â†’ DFS with cycle detection
â”‚
â””â”€â”€ Dependency ordering â†’ Topological Sort (DFS)
```

## Dynamic Programming vs. Greedy Algorithms

| Characteristic | Dynamic Programming | Greedy Algorithm |
|----------------|---------------------|------------------|
| **Approach** | Breaks problem into subproblems and stores results | Makes locally optimal choice at each step |
| **Optimality** | Guarantees optimal solution | May not find optimal solution |
| **Time Complexity** | Often polynomial, depends on state space | Usually more efficient than DP |
| **Use When** | Overlapping subproblems<br>Optimal substructure<br>Finding all solutions | Making local choices leads to global optimum<br>Performance critical<br>Approximate solution acceptable |
| **Examples** | Knapsack, Longest Common Subsequence, Edit Distance | Huffman coding, Dijkstra's, Interval scheduling |

### Decision Tree for Optimization Problems

```
Does the problem have optimal substructure?
â”œâ”€â”€ Yes â†’ Does it have overlapping subproblems?
â”‚        â”œâ”€â”€ Yes â†’ Dynamic Programming
â”‚        â””â”€â”€ No â†’ Consider divide and conquer
â”‚
â””â”€â”€ No â†’ Can locally optimal choices lead to global optimum?
         â”œâ”€â”€ Yes â†’ Greedy Algorithm
         â””â”€â”€ No â†’ May need other approaches (backtracking, branch and bound)
```

## String Algorithms

| Algorithm | Time Complexity | Space Complexity | Best For | Avoid When |
|-----------|----------------|------------------|----------|------------|
| **Naive String Matching** | O(nÂ·m) | O(1) | Short strings<br>Simple cases | Performance critical<br>Long texts |
| **KMP Algorithm** | O(n+m) | O(m) | Single pattern matching<br>No preprocessing overhead | Multiple patterns |
| **Rabin-Karp** | O(n+m) average<br>O(nÂ·m) worst | O(1) | Multiple pattern matching | Worst case unacceptable |
| **Boyer-Moore** | O(n/m) best<br>O(nÂ·m) worst | O(k) k=alphabet size | Long patterns<br>Large alphabets | Small patterns<br>Preprocessing overhead |
| **Suffix Tree/Array** | O(n) construction<br>O(m) search | O(n) | Multiple searches on same text<br>Substring problems | Memory constraints<br>Single search |
| **Trie** | O(m) search/insert | O(ALPHABET_SIZEÂ·KEY_LENGTHÂ·n) | Prefix matching<br>Autocomplete | Memory constraints<br>Infrequent lookups |

### Decision Tree for String Problems

```
What's your string problem?
â”œâ”€â”€ Pattern matching
â”‚     â”œâ”€â”€ Single search on text?
â”‚     â”‚     â”œâ”€â”€ Short pattern â†’ Naive might be sufficient
â”‚     â”‚     â””â”€â”€ Longer pattern â†’ KMP or Boyer-Moore
â”‚     â”‚
â”‚     â””â”€â”€ Multiple searches on same text?
â”‚           â”œâ”€â”€ Memory available â†’ Build Suffix Tree/Array
â”‚           â””â”€â”€ Memory constrained â†’ Rabin-Karp
â”‚
â”œâ”€â”€ Dictionary operations?
â”‚     â”œâ”€â”€ Exact matches â†’ Hash Table
â”‚     â””â”€â”€ Prefix matching/autocomplete â†’ Trie
â”‚
â””â”€â”€ Edit distance/similarity?
      â””â”€â”€ Dynamic Programming approaches
```

## General Selection Guidelines

1. **Start simple**: Don't overengineer - use the simplest algorithm that meets requirements

2. **Consider constraints**:
   - Time complexity requirements
   - Memory limitations
   - Data characteristics (sorted, nearly sorted, range of values)
   - Expected input sizes
   - Frequency of operations

3. **Evaluate tradeoffs**:
   - Time vs. space complexity
   - Implementation complexity vs. performance gain
   - Average case vs. worst case
   - Code readability vs. optimization

4. **Remember constants matter**:
   - For small inputs, asymptotically slower algorithms may be faster
   - Cache performance and hardware considerations affect real-world performance
   - Modern language optimizations can change theoretical predictions

5. **Profile and measure**:
   - Theoretical analysis is a starting point
   - Real-world performance may differ
   - Different inputs can change algorithm behavior

## Web Development Specific Considerations

### Frontend Algorithm Selection

1. **UI Rendering and Animation**:
   - Prefer O(1) or O(log n) algorithms for frame-rate sensitive operations
   - Consider Web Workers for O(n) or slower operations
   - Virtual lists/windowing for large data sets

2. **State Management**:
   - Use normalized data with O(1) lookups for frequent updates
   - Consider immutable data structures for change detection
   - Balance memory usage against lookup speed

3. **Form Validation and Processing**:
   - Progressive validation for better UX over batch processing
   - Consider debouncing/throttling for expensive validations

### Backend Algorithm Selection

1. **API Design**:
   - Pagination/cursor-based iteration for large collections
   - Efficient indexing strategies for database queries
   - Caching for repeated computations

2. **Data Processing**:
   - Stream processing for large datasets
   - Batch processing for expensive operations
   - Consider parallelization for independent tasks

3. **Authentication/Security**:
   - Constant-time comparisons for sensitive data
   - Space-time tradeoffs for hashing/encryption

---

**Navigation**
- [â¬…ï¸ Previous: Data Structures Complexity](./06-data-structures-complexity.md)
- [â¬†ï¸ Up to Theory Index](./00-index.md)
- [â¡ï¸ Next: Complex Algorithm Analysis](./08-complex-algorithm-analysis.md)